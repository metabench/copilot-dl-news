#!/usr/bin/env node
/**
 * Test Log Cleanup Tool - Aggressive Deletion Strategy
 * 
 * Designed to minimize log file clutter (2000+ files can slow down AI scanning).
 * Uses worker threads for parallel log processing (10x faster than sequential).
 * 
 * DEFAULT STRATEGY (Very Aggressive - Recommended):
 * - Keep only 2 most recent "ALL" suite logs (latest + one fallback)
 * - Keep only 1 most recent log per suite type (unit, integration, e2e)
 * - NO time-based retention (ignore age entirely)
 * - Result: Typically keeps 3-5 logs total, deletes 2,280+ files
 * 
 * Usage:
 *   node tools/cleanup-test-logs.js            # Dry run (show what would be deleted)
 *   node tools/cleanup-test-logs.js --execute  # Delete files (DEFAULT: keep 2 recent)
 *   node tools/cleanup-test-logs.js --keep 5   # Keep 5 most recent logs instead of 2
 *   node tools/cleanup-test-logs.js --all-only # Keep ONLY "ALL" suite logs (ignore others)
 *   node tools/cleanup-test-logs.js --stats    # Show statistics without deleting
 *   node tools/cleanup-test-logs.js --parallel 4 # Use 4 worker threads (default: 2)
 */

const fs = require('fs');
const path = require('path');
const { Worker } = require('worker_threads');
const os = require('os');

// Configuration
const ROOT_DIR = path.join(__dirname, '..');
const TESTLOGS_DIR = path.join(ROOT_DIR, 'testlogs');

// Parse command line args
const args = process.argv.slice(2);
const dryRun = !args.includes('--execute');
const showStats = args.includes('--stats');
const allOnlyMode = args.includes('--all-only');

// Parse keep count
const keepIdx = args.indexOf('--keep');
const keepRecentCount = keepIdx >= 0 ? parseInt(args[keepIdx + 1], 10) : 2;

// Parse worker count
const parallelIdx = args.indexOf('--parallel');
const parallelCount = parallelIdx >= 0 ? parseInt(args[parallelIdx + 1], 10) : 2;
const workerCount = Math.min(parallelCount, os.cpus().length, 4); // Cap at 4 to avoid overhead

/**
 * Worker thread script for parsing log metadata in parallel
 */
const workerScript = `
const { parentPort } = require('worker_threads');
const fs = require('fs');
const path = require('path');

function parseLogMetadata(filePath) {
  try {
    const content = fs.readFileSync(filePath, 'utf8');
    
    // Extract timestamp from filename
    const filename = path.basename(filePath);
    const timestampMatch = filename.match(/(\\d{4}-\\d{2}-\\d{2}T[\\d:-]+Z)/);
    const timestamp = timestampMatch ? timestampMatch[1] : null;
    
    // Count failures from summary
    const failMatch = content.match(/Tests?:\\s+(\\d+)\\s+failed/);
    const passMatch = content.match(/Test Suites?:\\s+(\\d+)\\s+passed/);
    const totalMatch = content.match(/Tests?:\\s+(\\d+)\\s+total/);
    const fileMatch = content.match(/Test Files?:\\s+(\\d+)\\s+total/);
    
    const failedTests = failMatch ? parseInt(failMatch[1], 10) : 0;
    const passedSuites = passMatch ? parseInt(passMatch[1], 10) : 0;
    const totalTests = totalMatch ? parseInt(totalMatch[1], 10) : 0;
    const totalFiles = fileMatch ? parseInt(fileMatch[1], 10) : 0;
    
    // Detect suite from filename
    let suite = 'unknown';
    if (filename.includes('_ALL.log')) suite = 'ALL';
    else if (filename.includes('_unit.log')) suite = 'unit';
    else if (filename.includes('_integration.log')) suite = 'integration';
    else if (filename.includes('_e2e')) suite = 'e2e';
    else if (filename.includes('_all.log')) suite = 'all';
    
    const stats = fs.statSync(filePath);
    
    return {
      filename,
      timestamp,
      suite,
      totalTests,
      totalFiles,
      failedTests,
      passedSuites,
      size: stats.size,
      mtime: stats.mtime.getTime(),
      isFailing: failedTests > 0
    };
  } catch (error) {
    return null;
  }
}

parentPort.on('message', (filePath) => {
  const result = parseLogMetadata(filePath);
  parentPort.postMessage(result);
});
`;

/**
 * Process logs using worker threads for parallelization
 */
async function parseLogsParallel(logPaths) {
  return new Promise((resolve, reject) => {
    const results = [];
    let completed = 0;
    const workerPool = [];

    const createWorker = () => {
      const worker = new Worker(workerScript, { eval: true });
      worker.on('error', reject);
      worker.on('exit', (code) => {
        if (code !== 0) reject(new Error(`Worker exited with code ${code}`));
      });
      return worker;
    };

    // Create worker pool
    for (let i = 0; i < workerCount; i++) {
      workerPool.push(createWorker());
    }

    let taskIndex = 0;
    let activeJobs = 0;

    const processNext = () => {
      if (taskIndex >= logPaths.length && activeJobs === 0) {
        // All done
        workerPool.forEach(w => w.terminate());
        resolve(results);
        return;
      }

      if (taskIndex >= logPaths.length) {
        return; // No more tasks
      }

      const filePath = logPaths[taskIndex];
      const workerIdx = taskIndex % workerCount;
      const worker = workerPool[workerIdx];
      taskIndex++;
      activeJobs++;

      const handler = (result) => {
        if (result) results.push({ path: filePath, ...result });
        activeJobs--;
        completed++;
        
        if (completed % 50 === 0) {
          process.stdout.write(`  Scanned: ${completed}/${logPaths.length} logs\r`);
        }

        // Process next task
        processNext();
      };

      worker.once('message', handler);
      worker.postMessage(filePath);
    };

    // Start all workers
    for (let i = 0; i < Math.min(workerCount, logPaths.length); i++) {
      processNext();
    }
  });
}

/**
 * Select logs to keep based on aggressive strategy
 */
function selectLogsToKeep(logsWithMeta) {
  const byType = {};
  
  // Group logs by suite type
  for (const log of logsWithMeta) {
    if (!byType[log.suite]) {
      byType[log.suite] = [];
    }
    byType[log.suite].push(log);
  }
  
  // Sort each group by modification time (newest first)
  for (const suite in byType) {
    byType[suite].sort((a, b) => b.mtime - a.mtime);
  }
  
  const toKeep = [];
  
  if (allOnlyMode) {
    // Keep only ALL suite logs
    if (byType['ALL']) {
      toKeep.push(...byType['ALL'].slice(0, keepRecentCount));
    }
  } else {
    // Default: keep top N from each suite type
    for (const suite in byType) {
      // For ALL suite, keep more (it's comprehensive)
      const keepCount = suite === 'ALL' ? Math.max(keepRecentCount, 2) : Math.min(keepRecentCount, 1);
      toKeep.push(...byType[suite].slice(0, keepCount));
    }
  }
  
  return toKeep;
}

/**
 * Main cleanup logic
 */
async function cleanupTestLogs() {
  console.log('\nüßπ TEST LOG CLEANUP TOOL (Aggressive Strategy)\n');
  console.log('‚ïê'.repeat(80));
  
  if (dryRun && !showStats) {
    console.log('üîç DRY RUN MODE - No files will be deleted\n');
    console.log('   Use --execute to actually delete files\n');
  }
  
  // Check testlogs directory exists
  if (!fs.existsSync(TESTLOGS_DIR)) {
    console.log('‚úÖ testlogs/ directory does not exist (nothing to clean)');
    return;
  }
  
  // Get all log files (.log and .failures.json)
  const allLogFiles = fs.readdirSync(TESTLOGS_DIR)
    .filter(f => f.endsWith('.log') || f.endsWith('.failures.json'))
    .map(f => path.join(TESTLOGS_DIR, f));
  
  // Get only .log files for parsing
  const allLogs = allLogFiles.filter(f => f.endsWith('.log'));
  
  if (allLogs.length === 0) {
    console.log('‚úÖ No log files found in testlogs/');
    return;
  }
  
  console.log(`üìä Found ${allLogs.length} log files in testlogs/\n`);
  console.log(`üîç Analyzing logs using ${workerCount} worker threads...\n`);
  
  try {
    // Parse metadata in parallel using workers
    const logsWithMeta = await parseLogsParallel(allLogs);
    
    console.log(`\n‚úÖ Scanned all ${logsWithMeta.length} logs\n`);
    
    if (logsWithMeta.length === 0) {
      console.log('‚ùå Could not parse any logs');
      return;
    }
    
    // Sort by modification time
    logsWithMeta.sort((a, b) => b.mtime - a.mtime);
    
    // Select logs to keep
    const toKeep = selectLogsToKeep(logsWithMeta);
    const keepSet = new Set(toKeep.map(l => l.filename));
    const toDelete = logsWithMeta.filter(l => !keepSet.has(l.filename));
    
    // Calculate stats
    const totalSize = logsWithMeta.reduce((sum, l) => sum + l.size, 0);
    const deleteSize = toDelete.reduce((sum, l) => sum + l.size, 0);
    const keepSize = toKeep.reduce((sum, l) => sum + l.size, 0);
    
    // Group by suite for summary
    const byType = {};
    for (const log of logsWithMeta) {
      if (!byType[log.suite]) byType[log.suite] = { total: 0, keeping: 0, deleting: 0 };
      byType[log.suite].total++;
      if (keepSet.has(log.filename)) {
        byType[log.suite].keeping++;
      } else {
        byType[log.suite].deleting++;
      }
    }
    
    // Display summary
    console.log('üìä CLEANUP SUMMARY:\n');
    console.log(`   Total logs: ${allLogs.length} (${(totalSize / 1024 / 1024).toFixed(1)} MB)`);
    console.log(`   Will keep: ${toKeep.length} (${(keepSize / 1024 / 1024).toFixed(1)} MB)`);
    console.log(`   Will delete: ${toDelete.length} logs + paired .failures.json files (${(deleteSize / 1024 / 1024).toFixed(1)} MB)`);
    console.log(`   Space reclaimed: ${(deleteSize / 1024 / 1024).toFixed(1)} MB\n`);
    
    // Show by suite
    console.log('üìã By Suite Type:\n');
    Object.entries(byType).sort().forEach(([suite, stats]) => {
      console.log(`   ${suite.padEnd(12)} ‚Üí Keep: ${stats.keeping.toString().padStart(2)} / Delete: ${stats.deleting.toString().padStart(4)}`);
    });
    console.log();
    
    if (showStats) {
      console.log('‚ïê'.repeat(80));
      return;
    }
    
    // Show what will be kept
    if (toKeep.length > 0) {
      console.log('üìå Keeping:\n');
      toKeep.forEach(log => {
        const age = Math.ceil((Date.now() - log.mtime) / (1000 * 60 * 60 * 24));
        const status = log.isFailing ? '‚ùå FAILING' : '‚úÖ PASSING';
        console.log(`   ${log.filename}`);
        console.log(`     Suite: ${log.suite.padEnd(12)} Age: ${age}d${log.totalTests > 0 ? ` Tests: ${log.totalTests}` : ''}  ${status}\n`);
      });
      console.log();
    }
    
    // Show sample of what will be deleted
    if (toDelete.length > 0) {
      console.log('üóëÔ∏è  Deleting (sample of first 15):\n');
      toDelete.slice(0, 15).forEach(log => {
        const age = Math.ceil((Date.now() - log.mtime) / (1000 * 60 * 60 * 24));
        console.log(`   √ó ${log.filename}`);
        console.log(`     Age: ${age}d, Suite: ${log.suite}, Size: ${(log.size / 1024).toFixed(0)} KB\n`);
      });
      if (toDelete.length > 15) {
        console.log(`   ... and ${toDelete.length - 15} more\n`);
      }
      console.log();
    }
    
    // Execute deletion if not dry run
    if (!dryRun && toDelete.length > 0) {
      console.log('üóëÔ∏è  Deleting old log files and their metadata...\n');
      
      let deleted = 0;
      let failed = 0;
      
      for (let i = 0; i < toDelete.length; i++) {
        const log = toDelete[i];
        try {
          fs.unlinkSync(log.path);
          deleted++;
          
          // Also delete associated .failures.json file if it exists
          const failuresPath = log.path.replace('.log', '.failures.json');
          if (fs.existsSync(failuresPath)) {
            fs.unlinkSync(failuresPath);
            deleted++;
          }
          
          if ((i + 1) % 100 === 0) {
            process.stdout.write(`  Progress: ${i + 1}/${toDelete.length} logs processed\r`);
          }
        } catch (error) {
          failed++;
          if (failed < 5) {
            console.error(`   ‚ö†Ô∏è  Failed to delete ${log.filename}: ${error.message}`);
          }
        }
      }
      
      console.log(`\n‚úÖ Deleted ${deleted} files${failed > 0 ? ` (${failed} failed)` : ''}\n`);
    }
    
    console.log('‚ïê'.repeat(80));
    
    if (dryRun) {
      console.log('\nüí° Run with --execute to actually delete files');
      console.log('üí° Use --keep N to keep N logs per suite (default: 2)');
      console.log('üí° Use --all-only to keep ONLY "ALL" suite logs');
      console.log('üí° Use --stats for statistics only (no deletion)');
    } else {
      console.log('\n‚úÖ Cleanup complete!');
    }
  } catch (error) {
    console.error('\n‚ùå Error during cleanup:', error.message);
    process.exit(1);
  }
}

// Main execution
cleanupTestLogs().catch(err => {
  console.error(err);
  process.exit(1);
});
