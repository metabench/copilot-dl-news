# Chapter 2: Data Flow

> **Implementation Status**: âœ… All phases implemented. See [Chapter 16](16-implementation-guide.md) for file locations.

## Codebase Quick Reference

| Phase | Key Files | Status |
|-------|-----------|--------|
| Discovery | `src/crawler/core/Crawler.js`, `src/crawler/planner/` | âœ… Complete |
| Download | `src/crawler/NewsCrawler.js`, `src/utils/compression.js` | âœ… Complete |
| Extraction | `src/utils/HtmlArticleExtractor.js`, `src/utils/ArticleXPathAnalyzer.js` | âœ… Complete |
| Analysis | `src/modules/analyse-pages-core.js`, `labs/analysis-observable/` | âœ… Complete |
| Disambiguation | `src/analysis/place-extraction.js`, `src/ui/server/placeHubGuessing/` | ğŸ”„ Partial |
| Export | `src/export/` | âœ… Complete |

## The Complete Pipeline

Data flows through the system in distinct phases, each with clear inputs and outputs.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PHASE 1: DISCOVERY                                â”‚
â”‚                                                                          â”‚
â”‚   Seed URL â”€â”€â–¶ Queue â”€â”€â–¶ Fetch â”€â”€â–¶ Parse Links â”€â”€â–¶ Filter â”€â”€â–¶ Queue     â”‚
â”‚                  â”‚                                              â”‚        â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                    â–¼                                      â”‚
â”‚                           Priority Planner                                â”‚
â”‚                     (scores URLs, manages depth)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PHASE 2: DOWNLOAD                                 â”‚
â”‚                                                                          â”‚
â”‚   Prioritized URL â”€â”€â–¶ Fetch HTML â”€â”€â–¶ Compress â”€â”€â–¶ Store                  â”‚
â”‚                                          â”‚                                â”‚
â”‚                                          â–¼                                â”‚
â”‚                              content_cache table                          â”‚
â”‚                          (zstd compressed HTML)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PHASE 3: EXTRACTION                               â”‚
â”‚                                                                          â”‚
â”‚   Compressed HTML â”€â”€â–¶ Decompress â”€â”€â–¶ XPath/Readability â”€â”€â–¶ Clean Text    â”‚
â”‚                                              â”‚                            â”‚
â”‚                                              â–¼                            â”‚
â”‚                                     articles table                        â”‚
â”‚                               (title, body, metadata)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PHASE 4: ANALYSIS                                 â”‚
â”‚                                                                          â”‚
â”‚   Article Text â”€â”€â–¶ Fact Extraction â”€â”€â–¶ Classification â”€â”€â–¶ Store          â”‚
â”‚        â”‚                  â”‚                   â”‚              â”‚            â”‚
â”‚        â”‚                  â–¼                   â–¼              â–¼            â”‚
â”‚        â”‚           article_facts      content_analysis    updates         â”‚
â”‚        â”‚                                                                  â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Place Detection â”€â”€â–¶ place_mentions table             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       PHASE 5: DISAMBIGUATION                             â”‚
â”‚                                                                          â”‚
â”‚   Place Mentions â”€â”€â–¶ Candidate Lookup â”€â”€â–¶ Score & Rank â”€â”€â–¶ Resolve       â”‚
â”‚                              â”‚                   â”‚              â”‚         â”‚
â”‚                              â–¼                   â–¼              â–¼         â”‚
â”‚                         gazetteer          aliases      resolved_places   â”‚
â”‚                         (places)       (multilang)     (final answer)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PHASE 6: EXPORT                                   â”‚
â”‚                                                                          â”‚
â”‚   Enriched Data â”€â”€â–¶ Format â”€â”€â–¶ Filter â”€â”€â–¶ Output                         â”‚
â”‚                                              â”‚                            â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚                              â–¼               â–¼               â–¼           â”‚
â”‚                            JSON            CSV            API            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Phase Details

### Phase 1: Discovery

**Purpose:** Find URLs worth downloading

**Components:**
- `src/crawler/core/Crawler.js` â€” Core crawl loop
- `src/crawler/planner/` â€” Priority planning
- `src/crawler/queue/` â€” URL queue management

**Key Tables:**
- None directly (queue is in-memory during crawl)

**Events Emitted:**
- `QUEUE` â€” URL enqueued/dequeued/dropped
- `PROGRESS` â€” Crawl progress updates

### Phase 2: Download

**Purpose:** Fetch and store HTML content

**Components:**
- `src/crawler/NewsCrawler.js` â€” Orchestrates downloads
- `src/utils/compression.js` â€” Zstd compression
- `src/db/adapters/` â€” Database writes

**Key Tables:**
- `content_cache` â€” Compressed HTML storage
- `articles` â€” Article metadata

**Events Emitted:**
- `PAGE` â€” Page downloaded
- `TELEMETRY` â€” Performance metrics

### Phase 3: Extraction

**Purpose:** Extract readable content from HTML

**Components:**
- `src/utils/HtmlArticleExtractor.js` â€” Article extraction
- `src/utils/ArticleXPathAnalyzer.js` â€” XPath-based extraction
- `@mozilla/readability` â€” Fallback extraction

**Key Decision:** XPath vs Readability
```
IF cached XPath pattern exists for domain:
  â†’ Use XPath extraction (fast: 50-200ms)
ELSE:
  â†’ Use JSDOM + Readability (slow: 10-30s for large pages)
```

### Phase 4: Analysis

**Purpose:** Extract structured facts and classifications

**Components:**
- `src/modules/analyse-pages-core.js` â€” Core analysis
- `labs/analysis-observable/` â€” Observable wrapper
- `src/facts/` â€” Fact extraction rules

**Key Tables:**
- `content_analysis` â€” Analysis results with version tracking
- `article_facts` â€” Extracted boolean facts
- `place_mentions` â€” Detected place references

**Version Tracking:**
```sql
-- Each analysis run increments the version
SELECT MAX(analysis_version) + 1 AS next_version FROM content_analysis;

-- Query pages needing analysis
SELECT * FROM content_analysis WHERE analysis_version < ?;
```

### Phase 5: Disambiguation

**Purpose:** Resolve place mentions to specific geographic entities

**Components:**
- See `docs/sessions/2026-01-04-gazetteer-progress-ui/book/`

**Key Tables:**
- `gazetteer` â€” Place definitions
- `aliases` â€” Multi-language place names
- `resolved_places` â€” Final disambiguation results

### Phase 6: Export

**Purpose:** Deliver enriched data to downstream systems

**Components:**
- `src/export/` â€” Export pipelines
- `tools/export-*.js` â€” CLI export tools

**Output Formats:**
- JSON (full fidelity)
- CSV (tabular)
- API (real-time)

---

## Data Volumes (Typical)

| Stage | Records | Storage |
|-------|---------|---------|
| URLs discovered | ~500k | Queue (memory) |
| Pages downloaded | ~50k | ~2GB compressed |
| Articles extracted | ~48k | ~500MB text |
| Analysis results | ~48k | ~100MB |
| Place mentions | ~200k | ~50MB |
| Resolved places | ~150k | ~30MB |

---

## Timing Expectations

| Operation | Time | Notes |
|-----------|------|-------|
| Crawl 100 pages | 2-5 min | Depends on site response |
| Analyze 100 pages | 2-10 min | XPath fast, JSDOM slow |
| Full 48k analysis | 4-12 hours | With bottlenecks |
| Disambiguation 200k | ~30 min | Database-bound |

---

## Error Propagation

Errors at each phase have different impacts:

| Phase | Error Type | Impact | Recovery |
|-------|------------|--------|----------|
| Discovery | Network timeout | Skip URL | Retry queue |
| Download | HTTP 404/500 | No content | Mark failed |
| Extraction | Parse failure | No article | Log, skip |
| Analysis | Exception | No facts | Retry later |
| Disambiguation | No match | Unresolved | Human review |

---

## Next Chapter

[Chapter 3: Database Schema â†’](03-database-schema.md)
